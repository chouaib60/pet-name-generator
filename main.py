import os
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains.llm import LLMChain

# Charger les variables d'environnement
load_dotenv()

def namePet(animal_type):
    # V√©rification de la cl√© API
    api_key = os.getenv("OPENAI_API_KEY")
    print(f"üîë Cl√© API charg√©e: {'Oui' if api_key else 'Non'}")
    
    if not api_key:
        return "‚ùå ERREUR: OPENAI_API_KEY non trouv√©e dans .env"
    
    try:
        # Initialisation du mod√®le
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.9,
            api_key=api_key
        )
        
        # Prompt template
        prompt_template = PromptTemplate(
            input_variables=["animal_type"],
            template="I have a {animal_type} pet. Suggest 5 good names for it."
        )
        
        # Cr√©ation de la cha√Æne
        name_chain = LLMChain(llm=llm, prompt=prompt_template)
        
        # Ex√©cution
        response = name_chain.run({"animal_type": animal_type})
        return response
        
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

if __name__ == "__main__":
    print("üöÄ Test de l'application...")
    result = namePet("cat")
    print("üêæ R√©sultat:")
    print(result)